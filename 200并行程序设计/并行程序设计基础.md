---
date: 
tags:
  - study
---
21世纪初，处理器的设计方式发生了巨大的变化。尽管晶体管密度增长，但如果仔细分析，会发现很多地方都发生了显著的变化。曾经按照摩尔定律增长的处理器时钟频率开始变得停滞不前，处理器生产商开始从在管芯上设计单核处理器转向多核处理器，通常也被成为多核。从物理的角度看，转向多核设计的原因在于设计更高性能（更深或更宽的流水线）的单核处理器所带来的功耗密度增长无法接受。这也是处理器设计的第二次遭遇功耗的物理限制，第一次遭遇导致处理器设计由双极型晶体管全面转向更高功效的互补金属氧化物半导体CMOS晶体管，而这次暂未出现可以代替CMOS晶体管的功效更高的技术，因此功耗限制需要通过体系结构的改变来解决，即从单核转向多核。
## 为什么要并行计算

### 1.1为什么要并行设计

- 不断提升的计算能力已经成为许多飞速发展领域（如科学、互联网、娱乐等）的核心力量
- 因为对于单处理器而言，其性能的提升实际是提高了处理器上晶体管的密度，但受限于散热问题等，密度无法一直提升。如果考虑并行化，即生产多个相对简单的完整处理器放在一个芯片上，即多核处理器，就能解决密度问题。
- 大多数传统单核系统编写的程序无法利用多核处理器，并行程序能充分发挥多核处理器的优势，然而将串行程序改写成并行程序并不顺利。
### 1.2怎么样编写并行程序

最广泛的两种方式：任务并行和数据并行

- 任务并行是指将待解决问题所需要执行 的各个任务分配到各个核上执行
- 数据并行是指将待解决问题所需要处理的数据分配给各个核， 每个核在分配到的数据集上执行大致相似的操作

基本思想：将要完成的任务分配给各个核。

- 通信：一个或多个核将自己的部分和结果发送给其他的核。
- 负载平衡：给每个核分配大致相同数目的数据
- 同步

两种主要并行系统：

- 共享内存系统
- 核心可以共享对计算机内存的访问；
- 原则上，每个核都可以读写每个内存位置。（Pthreads, OpenMP）
- 分布式内存系统
- 每个核都有自己的私有内存
- 核必须通过通过网络发送消息之类的方式显式通信。（MPI）
### 1.3并发、并行、分布式

- 并发：一个程序的多个任务在同一个时段内可以同时执行
- 并行：一个程序通过多个任务紧密协作来解决某个问题
- 分布式：一个程序需要与其他程序协作来解决某个问题

---

## 并行硬件与软件

### 2.1背景知识

2.1.1经典的冯·诺依曼结构：

经典的冯·诺依曼结构包括主存、 中央处理单元(Central Processing Unit, CPU)处理器核， 以及主存和CPU之间的互连结构。

中央处理单元分为控制单元和算术逻辑单元(ArithmeticLogic Unit, ALU)。

控制单元：负责决定应该执行程序中的哪些指令。

ALU：负责执行指令。

寄存器：CPU中的数据和程序执行时的状态信息，存储在特殊的快速存储介质中。

程序计数器：控制单元的一个特殊的寄存器，用来存放下一条指令的地址。

冯·诺依曼瓶颈：主存和cpu分离，由于对计算速度的需求，cpu的发展远远快于主存，限制了指令和数据的访问速率。

2.1.2 进程、 多任务及线程

操作系统(Operating System)：用来管理计算机的软件和硬件资源的主要软件。

进程：运行着的程序的一个实例。一个进程包括如下实体：

一块内存空间，包括可执行代码，一个用来跟踪执行函数的调用栈、 一个堆，以及其他内存区域，可执行的机器语言程序。

操作系统分配给进程的资源描述符，如文件描述符。

安全信息，例如阐述进程能够访问哪些硬件和软件的信息。

进程状态信息，例如进程是否就绪还是等待某些资源、寄存器内容，以及关于进程存储空间的信息。

  
线程：由进程启动，它不需要独立包含相关数据及信息，终止与开启比进程要快得多。线程具有许多传统进程所具有的特征，故又称为轻型进程(Light—Weight Process)

根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位

资源开销：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。

包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。

内存分配：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的

影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。

执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

### 2.1.3多进程和多线程区别

多进程：操作系统中同时运行的多个程序

多线程：在同一个进程中同时运行的多个任务

### 2.2 对冯·诺依曼模型的改进

2.2.1 Cache基础知识

高速缓冲存储器(cache, 简称缓存） 的访问时间比其他存储区域的访问时间短

CPU Cache 是一组相比于主存，CPU能更快速地访问的内存区域。

局部性原理：在访问完一个内存区域（指令或数据），程序会在不久的将来（时间局部性）访问邻近的区域（空间局部性）

写直达（write-through）：当CPU向Cache写数据时，高速缓存行会立即写入主存中。

写回（write-back）：数据不是立即更新到主存中，而是将发生数据更新的高速缓存行标记为脏（dirty）。当发生高速缓存行替换时，标记为脏的高速缓存行被写入主存中。

cache映射：

- 全相联：每个高速缓存行能够放置在Cache中的任意位置。
- 直接映射：每个高速缓存行在Cache中有唯一的位置。
- n路组相联：每个高速缓存行都能放置到Cache中n 个不同区域位置中的一个。

2.2.2 虚拟存储器

虚拟内存：是一种抽象的内存管理机制，允许操作系统使用硬盘空间作为扩展内存，使程序能够使用比实际物理内存更大的地址空间。使得主存可以作为辅存的缓存。

交换空间：它通过在主存中存放当前执行程序所需要用到的部分，来利用时间和空间局部性；那些暂时用不到的部分存储在辅存的块中。

虚拟地址分为两部分：虚拟页号和页内字节偏移量

转译后备缓冲区（TLB）：在快速缓存介质中缓存了一些页表的条目（通常16~512条）

### 2.2.3指令级并行

通过让多个处理器部件或者功能单元同时执行指令来提高处理器的性能。

实现指令集并行：

流水线：将功能单元分阶段安排，k个阶段的流水线不可能达到k倍的性能提高。

多发射：让多条指令同时启动。多发射处理器复制功能单元，并尝试同时执行程序中的不同指令。

静态多发射：功能单元是在编译时调度的。

动态多发射：功能单元是在运行时调度的。支持动态多问题的处理器有时被称为超标量（superscalar）。

2.2.4硬件多线程

线程级并行性(Thread-level parallelism, TLP)：试图通过同时执行不同的线程来提供并行性，因此它提供了比ILP更粗粒度的并行性，也就是说，同时执行的程序单元(线程)比细粒度的单元(单个指令)更大或更粗。

硬件多线程(Hardware multithreading)：为系统提供了一种方法，当当前正在执行的任务处于停滞（stalled）状态时，系统可以继续执行其他有用的任务。

细粒度 (fine-grained)： 处理器在每条指令执行完后切换线程，从而跳过被阻塞的线程。缺点是，执行很长一段指令的线程在执行每条指令的时候都需要等待。

粗粒度 (coarse-grained)：切换那些需要等待较长时间才能完成操作（如从主存中加载）而被阻塞的线程。优点是， 不需要线程间的立即切换

同步多线程(Simultaneous Multi threading, SMT)：细粒度多线程的变种。它通过允许多个线程同时使用多个功能单元来利用超标量处理器的性能。如果我们指定“优先＂线程，那么能够在一定程度上减轻线程减速的问题。优先线程是指有多条指令就绪的线程。

### 2.3 并行硬件

如果能够通过修改源代码而开发并行性或者必须修改源代码来开发并行性，那么我们认为这种硬件是并行硬件。

单指令流单数据流（SISD) ——冯·诺依曼系统

2.3.1 单指令多数据流(SIMD——Single Instruction Multiple Data)

向量寄存器：它是能够存储由多个操作数组成的向量，并且能够同时对其内容进行操作的寄存器。地址的长度由系统决定，从4到128个64位元素不等。

向量化和流水化的功能单元。

向量指令: 这些是在向量上操作而不是在标量上操作的指令。

交叉存储器

步长式存储器访问和硬件散射／聚集：程序能够访问向械中固定 间隔的元素。散射／聚集是对无规律间隔的数据进行读（聚集）和写（散射）

2.3.2 多指令多数据流(MIMD)

MIMD系统通常是异步的，即各个处理器能够按它们自己的节奏运行。

共享内存系统：每个处理器能够访问每个内存区域，处理器通过访问共享的数据结构来隐式地通信。

- 统一内存访问：对于所有的核来说，访问所有内存位置的时间是相同的，即同时的。UMA系统通常更容易编程，因为程序员不需要担心访问不同内存位置的时间不同。

- 非统一内存访问：访问与核直接相连的存储器位置，比必须通过另一个芯片访问该存储器的位置更快。NUMA系统比UMA系统能使用更多的内存。


分布式内存系统：每个处理器有自己私有的内存空间，处理器－内存对之间通过互连网络相互通信，通过发送消息或者使用特殊的函数来访问其他处理器的内存，从而进行显式的通信

最广泛的分布式内存系统称为集群

### 2.4 并行软件

2.4.1 注意事项

单程序多数据流(SPMD):仅包含一段可执行代码，通过使用条件转移语句，可以让这一段代码在执行时表现得像是在不同处理器上执行不同的程序。既可以实现数据并行也可以实现指令并行。

2.4.2 进程或线程的协调

负载均衡：在进程／线程之间平均分配任务。使得每个进程/线程获得大致的工作量，并且使得通信量最小化。

并行化 (parallelization)：将串行程序或者算法转换为并行程序的过程。

2.4.3 共享内存

动态线程

- 通常有一个主线程，并且在任何给定时刻都有一个(可能是空的)工作线程集合。

- 有效地利用了系统资源，因为线程所需要的资源只在线程实际运行时才会被使用。


静态线程

- 在资源使用方面效率较低，如果一个线程是空闲的，它的资源(例如，堆栈，程序计数器，等等)都不能被释放。

- 优点是，它更接近于最广泛使用的分布式内存编程范例。

- 在主线程进行任何必要的设置之后会fork出所有的线程，这些线程一直运行直到所有的工作完成。


非确定性

如果处理器是异步执行的，那就可能引发非确定性。

临界区：一次只能被一个线程执行的代码块。

保证互斥执行的最常用机制是互斥锁 (mutual exclusion clock) ， 或者互斥量 (mutex) ， 或者锁 (lock) 。

2.4.4 分布式内存

消息传递

API（至少） 要提供一个发送函数和 一个接收函数。

对于消息传递，最常使用的 API 是消息传递接口 (Message Passing Interface, MPI) 。

单向通信

### 2.5 性能

2.5.1 加速比和效率

在N核的系统上运行，那么并行程序的运行速度就是串行程序的p倍（假设程序百分比可并行，不考虑通信）。此时我们称并行程序有线性加速比。

事实上我们不可能获得线性加速比，因为多个线程/进程总是会要引入一些代价。

并行程序的加速比：S=

效率：

2.5.2 阿姆达尔定律（悲观）

除非一个串行程序的执行几乎全部都并行化，否则，不论有多少可以利用的核，通过并行化所产生的加速比都会是受限的。得出了提高加速比的关键在于，并行运行时间较大的那一部分。

2.5.3 可扩展性

我们增加该程序所用的进程／线程数， 如果在输入规模也以相应增长率增加的情况下，该程序的效率值一直都是 E, 那么我们就称该程序是可扩展的。

强可扩展：在增加进程／线程的个数时，可以维持固定的效率，却不增加问题的规模。

弱可扩展：增加进程／线程个数的同时， 只有以相同倍率增加问题的规模才能使效率值保持不变。

### 2.6 并行程序设计

并行化步骤

**划分:将要执行的指令和数据按照计算部分拆分成多个小任务。**

**通信:确定上一步所识别出来的任务之间需要执行哪些通信。**

**凝聚或聚合:将第一步所确定的任务与通信结合成更大的任务。**

**分配:将上一步聚合好的任务分配到进程／线程中。这一步还要使通信最小化，使各个进程／线程所得到的工作最大致均衡。**


###  2.7粗粒度与细粒度的区别

粗粒度 (Coarse-grained): 任务被分解成相对较大的子任务。每个子任务包含大量的计算或操作，执行时间较长。 线程间的同步开销相对较小，但可能导致某些核心空闲时间较长，降低并行效率。适合那些计算密集型任务，或者任务之间依赖性较弱的情况。

细粒度 (Fine-grained): 任务被分解成许多小的子任务。每个子任务执行时间较短，计算量较小。 线程间的同步开销相对较大，因为线程频繁地进行同步和切换上下文，但可以实现更高的并行度，更好地利用多核处理器的资源。适合那些 I/O 密集型任务，或者任务之间依赖性较强的情况。

---